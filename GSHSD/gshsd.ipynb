{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-22T14:56:47.271712Z","iopub.status.busy":"2022-03-22T14:56:47.271175Z","iopub.status.idle":"2022-03-22T14:56:51.256810Z","shell.execute_reply":"2022-03-22T14:56:51.255969Z","shell.execute_reply.started":"2022-03-22T14:56:47.271623Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/HuangRihChang/GSHSD.git\n","%cd GSHSD/GSHSD\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:56:52.755890Z","iopub.status.busy":"2022-03-22T14:56:52.755147Z","iopub.status.idle":"2022-03-22T14:56:59.486604Z","shell.execute_reply":"2022-03-22T14:56:59.485849Z","shell.execute_reply.started":"2022-03-22T14:56:52.755852Z"},"trusted":true},"outputs":[],"source":["import functools\n","\n","import torch\n","from torch import nn\n","from model.model import TransformerEncoder\n","from model.metrices import F1Score\n","from model.losses.softmax import CenterLoss\n","from HSDDataset import ViHSDData\n","\n","from torch.utils.data import DataLoader, RandomSampler\n","from tqdm.notebook import tqdm\n","# from tqdm import tqdm\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.tensorboard import SummaryWriter\n","from utils import get_device\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","import numpy as np\n","import emoji\n","import re\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:56:59.490603Z","iopub.status.busy":"2022-03-22T14:56:59.490380Z","iopub.status.idle":"2022-03-22T14:56:59.541503Z","shell.execute_reply":"2022-03-22T14:56:59.540648Z","shell.execute_reply.started":"2022-03-22T14:56:59.490575Z"},"trusted":true},"outputs":[],"source":["LR = 1e-4\n","n_epochs = 25\n","classes_num = 3\n","batch_size = 64\n","checkpoint_batch_size = 1024\n","max_len = 128\n","device = get_device()\n","\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:57:00.375721Z","iopub.status.busy":"2022-03-22T14:57:00.374997Z","iopub.status.idle":"2022-03-22T14:57:00.380811Z","shell.execute_reply":"2022-03-22T14:57:00.379809Z","shell.execute_reply.started":"2022-03-22T14:57:00.375684Z"},"trusted":true},"outputs":[],"source":["def proprocess(x):\n","    x = str(x)\n","    x = emoji.replace_emoji(x, replace='')\n","    x = re.sub(r\" +\", \" \", x)\n","    return x.lower().strip()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random\n","\n","unk_token = '[UNK]'\n","\n","def get_item(row, mask_rate=0.5):\n","    utterance, hate_label = row[\"free_text\"], row[\"label_id\"]\n","    utterance = utterance.split()\n","    mask_rate = random.uniform(0., mask_rate)\n","    start = random.randint(0,len(utterance))\n","    end = min(random.randint(start,len(utterance)), start+int(len(utterance)*mask_rate))\n","    tmp = utterance[0:start] + [unk_token]*(end-start) + utterance[end:]\n","    utterance = \" \".join(tmp)\n","    return utterance, hate_label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:57:00.786361Z","iopub.status.busy":"2022-03-22T14:57:00.785902Z","iopub.status.idle":"2022-03-22T14:57:03.205144Z","shell.execute_reply":"2022-03-22T14:57:03.204359Z","shell.execute_reply.started":"2022-03-22T14:57:00.786317Z"},"trusted":true},"outputs":[],"source":["model_collate_fn = functools.partial(lambda x: x)\n","\n","\n","train_df = pd.read_csv(\"./data/vihsd/train.csv\")\n","max_ = 0\n","for i in range(len(train_df.label_id.unique())):\n","    tmp = train_df[train_df[\"label_id\"]==i]\n","    if len(tmp) >= max_:\n","        max_ = len(tmp)\n","\n","for i in range(len(train_df.label_id.unique())):\n","    tmp = train_df[train_df[\"label_id\"]==i]\n","    for _ in range(math.ceil(max_/len(tmp))-1):\n","        train_df = pd.concat([train_df, tmp])\n","\n","train_data = ViHSDData(train_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess,\n","                 augment_fnct=get_item,\n","                )\n","train_sampler = RandomSampler(train_data)\n","data_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n","\n","val_df = pd.read_csv(\"./data/vihsd/dev.csv\")\n","val_data = ViHSDData(val_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess\n","                )\n","val_sampler = RandomSampler(val_data)\n","val_loader = DataLoader(val_data, batch_size=batch_size, sampler=val_sampler, collate_fn=model_collate_fn)\n","\n","\n","test_df = pd.read_csv(\"./data/vihsd/test.csv\")\n","test_data = ViHSDData(test_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess\n","                )\n","test_sampler = RandomSampler(test_data)\n","test_loader = DataLoader(test_data, batch_size=batch_size, sampler=test_sampler, collate_fn=model_collate_fn)\n","\n","training_step = len(data_loader)*n_epochs\n","print(f\"Total {training_step} training steps for this dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:57:03.207590Z","iopub.status.busy":"2022-03-22T14:57:03.206722Z","iopub.status.idle":"2022-03-22T14:57:15.978915Z","shell.execute_reply":"2022-03-22T14:57:15.978163Z","shell.execute_reply.started":"2022-03-22T14:57:03.207549Z"},"trusted":true},"outputs":[],"source":["# Defining Model for specific fold \"vinai/phobert-base\"\n","model_path = \"../../../input/mbert-model/bert-base-multilingual-uncased\"\n","model_path = \"./weights/multiBERTuncased\"\n","\n","model = TransformerEncoder(model_path, classes_num = classes_num,\n","                            max_seq_length = max_len, \n","                            checkpoint_batch_size = checkpoint_batch_size,\n","                            dropout_rate = 0.5, \n","                            model_args = {\"output_hidden_states\":False}\n","                            )\n","\n","cross_entropy_loss = nn.CrossEntropyLoss()\n","center_loss = CenterLoss(num_classes=classes_num,\\\n","                         feat_dim = model.get_word_embedding_dimension()\n","                        )\n","\n","\n","model.to(device)\n","cross_entropy_loss.to(device)\n","center_loss.to(device)\n","\n","model_params = list(model.named_parameters()) # included all params from pooler and transformers\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","model_params = [{'params': [p for n, p in model_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n","                {'params': [p for n, p in model_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","               ]\n","\n","optimize_params = model_params + list(center_loss.parameters())\n","\n","optimizer = AdamW(optimize_params, lr=LR)\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps=training_step*0.5, \n","                                            num_training_steps=training_step\n","                                            )\n","\n","# for param in model.sent_encoder.embeddings.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:57:15.980742Z","iopub.status.busy":"2022-03-22T14:57:15.980029Z","iopub.status.idle":"2022-03-22T14:57:16.009285Z","shell.execute_reply":"2022-03-22T14:57:16.008383Z","shell.execute_reply.started":"2022-03-22T14:57:15.980704Z"},"trusted":true},"outputs":[],"source":["def make_batch(batch, tokenizer, max_len=\"dynamic\", device=\"cuda:0\"):\n","    text_list, labels = [text for text,_ in batch], [label for _,label in batch]\n","    \n","    if max_len == \"dynamic\":\n","        lengths = np.array([len(tokenizer.tokenize(x))+2 for x in text_list])\n","        max_len = int(lengths.max())\n","    \n","    labels = torch.LongTensor(labels).to(device)\n","    toks = tokenizer.batch_encode_plus(text_list, max_length=max_len, padding='max_length', truncation=True)\n","    ids, mask = (torch.LongTensor(toks[\"input_ids\"]).to(device), torch.LongTensor(toks[\"attention_mask\"]).to(device))\n","    inputs = {\"input_ids\": ids, \"attention_mask\": mask}\n","    return inputs, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:57:16.011645Z","iopub.status.busy":"2022-03-22T14:57:16.011368Z","iopub.status.idle":"2022-03-22T14:57:16.023770Z","shell.execute_reply":"2022-03-22T14:57:16.022913Z","shell.execute_reply.started":"2022-03-22T14:57:16.011589Z"},"trusted":true},"outputs":[],"source":["def train(data_loader, model, cross_entropy_loss, optimizer, scheduler, train_step):\n","    tk = tqdm(data_loader)\n","    f1 = F1Score()\n","    for x in tk:\n","        model.train()\n","        inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n","        optimizer.zero_grad()\n","        logits, features = model(inputs)\n","        celoss = cross_entropy_loss(logits, labels)\n","        loss = 0.5*center_loss(features, labels) + celoss\n","        loss.backward()\n","\n","        for param in center_loss.parameters():\n","            # lr_cent is learning rate for center loss, e.g. lr_cent = 0.5\n","            param.grad.data *= (0.01 / (0.5 * LR))\n","        \n","        optimizer.step()\n","        scheduler.step()\n","\n","        with torch.no_grad():\n","            model.eval()\n","            predict = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n","            macro_f1 = f1(predict+1, labels+1, \"macro\")\n","            tk.set_postfix(Epoch=e, step=train_step, loss=loss.data.item(), f1=macro_f1[0].data.item())\n","        train_step += 1\n","    return train_step\n","\n","\n","def evaluation(dev_loader, model, cross_entropy_loss):\n","    f1 = F1Score()\n","    logits_list, labels_list = [], []\n","    model.eval()\n","    with torch.no_grad():\n","        for x in dev_loader:\n","            inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n","            logits, _ = model(inputs)\n","            logits_list.append(logits)\n","            labels_list.append(labels)\n","        labels = torch.cat(labels_list, dim=0)\n","        logits = torch.cat(logits_list, dim=0)\n","        predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n","        macro_f1 = f1(predicts+1, labels+1, \"macro\")\n","        loss = cross_entropy_loss(logits, labels)\n","        print(f\"Epoch {e} - loss: {loss.data.item()} - F1: {macro_f1[0].data.item()}\")\n","    return logits, labels, loss, macro_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T14:57:16.025404Z","iopub.status.busy":"2022-03-22T14:57:16.025081Z","iopub.status.idle":"2022-03-22T16:43:43.645041Z","shell.execute_reply":"2022-03-22T16:43:43.643941Z","shell.execute_reply.started":"2022-03-22T14:57:16.025369Z"},"trusted":true},"outputs":[],"source":["train_step = 0\n","for e in range(n_epochs):\n","    train_step = train(data_loader, model, cross_entropy_loss, optimizer, scheduler, train_step)\n","    evaluation(val_loader, model, cross_entropy_loss)\n","evaluation(test_loader, model, cross_entropy_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T16:43:47.219838Z","iopub.status.busy":"2022-03-22T16:43:47.219365Z","iopub.status.idle":"2022-03-22T16:44:15.004023Z","shell.execute_reply":"2022-03-22T16:44:15.003297Z","shell.execute_reply.started":"2022-03-22T16:43:47.219804Z"},"trusted":true},"outputs":[],"source":["logits, labels, loss, macro_f1 = evaluation(test_loader, model, cross_entropy_loss)\n","predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1).cpu().detach().numpy()\n","labels = labels.cpu().detach().numpy()\n","loss, macro_f1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix(labels, predicts)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
