{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-03-24T04:48:14.522452Z","iopub.status.busy":"2022-03-24T04:48:14.521916Z","iopub.status.idle":"2022-03-24T04:48:17.133772Z","shell.execute_reply":"2022-03-24T04:48:17.132927Z","shell.execute_reply.started":"2022-03-24T04:48:14.522412Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/HuangRihChang/GSHSD.git\n","%cd GSHSD/GSHSD\n","!ls"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:48:43.261151Z","iopub.status.busy":"2022-03-24T04:48:43.260858Z","iopub.status.idle":"2022-03-24T04:48:51.580044Z","shell.execute_reply":"2022-03-24T04:48:51.579248Z","shell.execute_reply.started":"2022-03-24T04:48:43.261102Z"},"trusted":true},"outputs":[],"source":["from IPython.display import clear_output\n","import time\n","\n","!rm ./ngrok \n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","clear_output()\n","!./ngrok authtoken 23DuHXStdM98jNNlyZIVaHNFktk_8agkCvS2XmfuiY1yR5izh"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-23T14:16:55.11769Z","iopub.status.busy":"2022-03-23T14:16:55.117467Z","iopub.status.idle":"2022-03-23T14:17:17.22198Z","shell.execute_reply":"2022-03-23T14:17:17.221074Z","shell.execute_reply.started":"2022-03-23T14:16:55.117663Z"},"trusted":true},"outputs":[],"source":["! rm -r ./runs/\n","! mkdir \"./runs/\"\n","\n","LOG_DIR = './runs/'\n","get_ipython().system_raw(f'tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 2111 &')\n","get_ipython().system_raw('./ngrok http 2111 &')\n","time.sleep(10)\n","clear_output()\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n","time.sleep(10)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:48:59.723673Z","iopub.status.busy":"2022-03-24T04:48:59.723185Z","iopub.status.idle":"2022-03-24T04:49:07.233936Z","shell.execute_reply":"2022-03-24T04:49:07.233124Z","shell.execute_reply.started":"2022-03-24T04:48:59.723629Z"},"trusted":true},"outputs":[],"source":["# Install the vncorenlp python wrapper\n","!pip install vncorenlp\n","\n","# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter) \n","!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/\n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n","\n","clear_output()\n","# !pip install tensorboard"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:11.360948Z","iopub.status.busy":"2022-03-24T04:49:11.360668Z","iopub.status.idle":"2022-03-24T04:49:11.372606Z","shell.execute_reply":"2022-03-24T04:49:11.371715Z","shell.execute_reply.started":"2022-03-24T04:49:11.360913Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'vncorenlp'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a6abf8e21841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvncorenlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVnCoreNLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSegmentation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./vncorenlp/VnCoreNLP-1.1.1.jar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdrsegmenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVnCoreNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wseg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_heap_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-Xmx500m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vncorenlp'"]}],"source":["from vncorenlp import VnCoreNLP\n","\n","class Segmentation:\n","    def __init__(self, api=\"./vncorenlp/VnCoreNLP-1.1.1.jar\", ):\n","        self.rdrsegmenter = VnCoreNLP(api, annotators=\"wseg\", max_heap_size='-Xmx500m')\n","\n","    def __call__(self, text):\n","        res = \"\"\n","        sentences = self.rdrsegmenter.tokenize(text.lower())\n","        for sentence in sentences:\n","            res += (\" \".join(sentence)) + \" \"\n","        return res.strip()"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:13.691614Z","iopub.status.busy":"2022-03-24T04:49:13.690941Z","iopub.status.idle":"2022-03-24T04:49:20.526711Z","shell.execute_reply":"2022-03-24T04:49:20.525943Z","shell.execute_reply.started":"2022-03-24T04:49:13.691574Z"},"trusted":true},"outputs":[],"source":["import functools\n","\n","import torch\n","from torch import nn\n","from model.model import TransformerEncoder\n","from model.metrices import F1Score\n","from model.losses.softmax import CenterLoss\n","from HSDDataset import ViHSDData\n","\n","from torch.utils.data import DataLoader, RandomSampler\n","from tqdm.notebook import tqdm\n","# from tqdm import tqdm\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.tensorboard import SummaryWriter\n","from utils import get_device\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","import numpy as np\n","import emoji\n","import re\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:20.528635Z","iopub.status.busy":"2022-03-24T04:49:20.528395Z","iopub.status.idle":"2022-03-24T04:49:20.587144Z","shell.execute_reply":"2022-03-24T04:49:20.586253Z","shell.execute_reply.started":"2022-03-24T04:49:20.528601Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu\n"]}],"source":["LR = 1e-5\n","n_epochs = 15\n","classes_num = 3\n","batch_size = 64\n","checkpoint_batch_size = 1024\n","max_len = 128\n","device = get_device()\n","\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:20.589292Z","iopub.status.busy":"2022-03-24T04:49:20.588474Z","iopub.status.idle":"2022-03-24T04:49:26.094388Z","shell.execute_reply":"2022-03-24T04:49:26.093430Z","shell.execute_reply.started":"2022-03-24T04:49:20.589252Z"},"trusted":true},"outputs":[],"source":["segmentator = Segmentation()\n","\n","def proprocess(x):\n","    x = str(x)\n","    x = emoji.replace_emoji(x, replace='')\n","    x = segmentator(x)\n","    x = re.sub(r\" +\", \" \", x)\n","    return x.lower().strip()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:26.098099Z","iopub.status.busy":"2022-03-24T04:49:26.097520Z","iopub.status.idle":"2022-03-24T04:49:33.152719Z","shell.execute_reply":"2022-03-24T04:49:33.151899Z","shell.execute_reply.started":"2022-03-24T04:49:26.098045Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ./weights/multiBERTuncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Defining Model for specific fold \"vinai/phobert-base\"\n","# model_path = \"../../../input/mbert-model/bert-base-multilingual-uncased\"\n","# model_path = \"../../../input/phobertpretrained\"\n","model_path = \"./weights/multiBERTuncased\"\n","\n","model = TransformerEncoder(model_path, classes_num = classes_num,\n","                            max_seq_length = max_len, \n","                            checkpoint_batch_size = checkpoint_batch_size,\n","                            dropout_rate = 0.5, \n","                            model_args = {\"output_hidden_states\":False}\n","                            )"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:33.154799Z","iopub.status.busy":"2022-03-24T04:49:33.154553Z","iopub.status.idle":"2022-03-24T04:49:33.163988Z","shell.execute_reply":"2022-03-24T04:49:33.163152Z","shell.execute_reply.started":"2022-03-24T04:49:33.154766Z"},"trusted":true},"outputs":[],"source":["import random\n","\n","unk_token = model.tokenizer.unk_token\n","\n","def get_item(row, mask_rate=0.4):\n","    utterance, hate_label = row[\"free_text\"], row[\"label_id\"]\n","    utterance = utterance.split()\n","    mask_rate = random.uniform(0., mask_rate)\n","    start = random.randint(0,len(utterance))\n","    end = min(random.randint(start,len(utterance)), start+int(len(utterance)*mask_rate))\n","    tmp = utterance[0:start] + [unk_token]*(end-start) + utterance[end:]\n","    utterance = \" \".join(tmp)\n","    return utterance, hate_label"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:49:33.165749Z","iopub.status.busy":"2022-03-24T04:49:33.165365Z","iopub.status.idle":"2022-03-24T04:54:41.804007Z","shell.execute_reply":"2022-03-24T04:54:41.802506Z","shell.execute_reply.started":"2022-03-24T04:49:33.165713Z"},"trusted":true},"outputs":[],"source":["model_collate_fn = functools.partial(lambda x: x)\n","\n","\n","train_df = pd.read_csv(\"./data/vihsd/train.csv\")\n","# max_ = 0\n","# for i in range(len(train_df.label_id.unique())):\n","#     tmp = train_df[train_df[\"label_id\"]==i]\n","#     if len(tmp) >= max_:\n","#         max_ = len(tmp)\n","\n","# for i in range(len(train_df.label_id.unique())):\n","#     tmp = train_df[train_df[\"label_id\"]==i]\n","#     for _ in range(math.ceil(max_/len(tmp))-1):\n","#         train_df = pd.concat([train_df, tmp])\n","\n","train_data = ViHSDData(train_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess,\n","                 augment_fnct=get_item,\n","                )\n","train_sampler = RandomSampler(train_data)\n","data_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n","\n","val_df = pd.read_csv(\"./data/vihsd/dev.csv\")\n","val_data = ViHSDData(val_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess\n","                )\n","val_sampler = RandomSampler(val_data)\n","val_loader = DataLoader(val_data, batch_size=batch_size, sampler=val_sampler, collate_fn=model_collate_fn)\n","\n","\n","test_df = pd.read_csv(\"./data/vihsd/test.csv\")\n","test_data = ViHSDData(test_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess\n","                )\n","test_sampler = RandomSampler(test_data)\n","test_loader = DataLoader(test_data, batch_size=batch_size, sampler=test_sampler, collate_fn=model_collate_fn)\n","\n","training_step = len(data_loader)*n_epochs\n","print(f\"Total {training_step} training steps for this dataset\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:54:41.806490Z","iopub.status.busy":"2022-03-24T04:54:41.805780Z","iopub.status.idle":"2022-03-24T04:54:46.626778Z","shell.execute_reply":"2022-03-24T04:54:46.625015Z","shell.execute_reply.started":"2022-03-24T04:54:41.806449Z"},"trusted":true},"outputs":[],"source":["cross_entropy_loss = nn.CrossEntropyLoss()\n","center_loss = CenterLoss(num_class=classes_num,\\\n","                         num_feature = model.get_word_embedding_dimension()\n","                        )\n","\n","\n","model.to(device)\n","cross_entropy_loss.to(device)\n","center_loss.to(device)\n","\n","model_params = list(model.named_parameters()) # included all params from pooler and transformers\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","model_params = [{'params': [p for n, p in model_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n","                {'params': [p for n, p in model_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","               ]\n","\n","opt_params = model_params\n","\n","model_optimizer = AdamW(opt_params, lr=LR)\n","model_scheduler = get_linear_schedule_with_warmup(model_optimizer,\n","                                            num_warmup_steps=training_step*0.5, \n","                                            num_training_steps=training_step\n","                                            )\n","\n","center_loss_params = list(center_loss.named_parameters())\n","center_loss_params = [{'params': [p for n, p in center_loss_params], 'weight_decay': 0.0},]\n","center_loss_optimizer = AdamW(center_loss_params, lr=0.01)\n","center_loss_scheduler = get_linear_schedule_with_warmup(center_loss_optimizer,\n","                                            num_warmup_steps=training_step*0.5, \n","                                            num_training_steps=training_step\n","                                            )\n","# for param in model.sent_encoder.embeddings.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:54:46.628366Z","iopub.status.busy":"2022-03-24T04:54:46.628106Z","iopub.status.idle":"2022-03-24T04:54:46.636581Z","shell.execute_reply":"2022-03-24T04:54:46.635748Z","shell.execute_reply.started":"2022-03-24T04:54:46.628331Z"},"trusted":true},"outputs":[],"source":["def make_batch(batch, tokenizer, max_len=\"dynamic\", device=\"cuda:0\"):\n","    text_list, labels = [text for text,_ in batch], [label for _,label in batch]\n","    \n","    if max_len == \"dynamic\":\n","        lengths = np.array([len(tokenizer.tokenize(x))+2 for x in text_list])\n","        max_len = int(lengths.max())\n","    \n","    labels = torch.LongTensor(labels).to(device)\n","    toks = tokenizer.batch_encode_plus(text_list, max_length=max_len, padding='max_length', truncation=True)\n","    ids, mask = (torch.LongTensor(toks[\"input_ids\"]).to(device), torch.LongTensor(toks[\"attention_mask\"]).to(device))\n","    inputs = {\"input_ids\": ids, \"attention_mask\": mask}\n","    return inputs, labels"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:54:46.638583Z","iopub.status.busy":"2022-03-24T04:54:46.638330Z","iopub.status.idle":"2022-03-24T04:54:46.656836Z","shell.execute_reply":"2022-03-24T04:54:46.656018Z","shell.execute_reply.started":"2022-03-24T04:54:46.638548Z"},"trusted":true},"outputs":[],"source":["def train(data_loader, model, cross_entropy_loss, center_loss, train_step):\n","    tk = tqdm(data_loader)\n","    f1 = F1Score()\n","    model.train()\n","    for x in tk:\n","        inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n","        if train_step == 0:\n","            writer.add_graph(model, inputs)\n","        \n","        logits, features = model(inputs)\n","        celoss = cross_entropy_loss(logits, labels)\n","        loss = celoss + 0.05*center_loss(features, labels)\n","        model_optimizer.zero_grad()\n","        center_loss_optimizer.zero_grad()\n","        loss.backward()\n","        for param in center_loss.parameters():\n","            if param.grad is not None:\n","                param.grad *= 1/0.05\n","        \n","        model_optimizer.step()\n","        center_loss_optimizer.step()\n","        model_scheduler.step()\n","        center_loss_scheduler.step()\n","        \n","        with torch.no_grad():\n","            predict = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n","            macro_f1 = f1(predict+1, labels+1, \"macro\")\n","            tk.set_postfix(Epoch=e, step=train_step, loss=loss.data.item(), f1=macro_f1[0].data.item())\n","            writer.add_scalar('loss', loss.data.item(), train_step)\n","            writer.add_scalar('celoss', celoss.data.item(), train_step)\n","            writer.add_scalar('macro_f1', macro_f1[0].data.item(), train_step)\n","        train_step += 1\n","    return train_step\n","\n","\n","def evaluation(dev_loader, model, cross_entropy_loss, prefix=None):\n","    f1 = F1Score()\n","    logits_list, labels_list = [], []\n","    model.eval()\n","    with torch.no_grad():\n","        for x in dev_loader:\n","            inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n","            logits, _ = model(inputs)\n","            logits_list.append(logits)\n","            labels_list.append(labels)\n","        labels = torch.cat(labels_list, dim=0)\n","        logits = torch.cat(logits_list, dim=0)\n","        predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n","        macro_f1 = f1(predicts+1, labels+1, \"macro\")\n","        loss = cross_entropy_loss(logits, labels)\n","        print(f\"Epoch {e} - loss: {loss.data.item()} - F1: {macro_f1[0].data.item()}\")\n","        if prefix is not None:\n","            writer.add_scalar(f'{prefix} celoss', loss.data.item(), e)\n","            writer.add_scalar(f'{prefix} macro_f1', macro_f1[0].data.item(), e)\n","    return logits, labels, loss, macro_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-23T14:23:07.850748Z","iopub.status.busy":"2022-03-23T14:23:07.850419Z","iopub.status.idle":"2022-03-23T17:03:04.236965Z","shell.execute_reply":"2022-03-23T17:03:04.236203Z","shell.execute_reply.started":"2022-03-23T14:23:07.850651Z"},"trusted":true},"outputs":[],"source":["train_step = 0\n","best_f1 = 0\n","best_loss = 1e8\n","for e in range(n_epochs):\n","    train_step = train(data_loader, model, cross_entropy_loss, center_loss, train_step)\n","    _, _, loss, macro_f1 = evaluation(val_loader, model, cross_entropy_loss,  prefix=\"val\")\n","    \n","    val_loss = loss.data.item()\n","    val_f1_score = macro_f1[0].data.item()\n","    \n","    if best_f1 <= val_f1_score:\n","        best_f1 = val_f1_score\n","        print(f\"Epcoh {e} Saving best f1_model with score {best_f1}\")\n","        torch.save(model.state_dict(), f\"best_f1.pth\")\n","    \n","    if best_loss >= val_loss:\n","        best_loss = val_loss\n","        print(f\"Epcoh {e} Saving best loss model with score {best_loss}\")\n","        torch.save(model.state_dict(), f\"best_loss.pth\")\n","\n","logits, labels, loss, macro_f1 = evaluation(test_loader, model, cross_entropy_loss)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:58:00.655657Z","iopub.status.busy":"2022-03-24T04:58:00.655188Z","iopub.status.idle":"2022-03-24T04:58:28.751051Z","shell.execute_reply":"2022-03-24T04:58:28.750315Z","shell.execute_reply.started":"2022-03-24T04:58:00.655622Z"},"trusted":true},"outputs":[],"source":["# model.load_state_dict(torch.load(\"../../../input/weights/best_f1.pth\"))\n","# model.eval()\n","e = 11\n","logits, labels, loss, macro_f1 = evaluation(test_loader, model, cross_entropy_loss)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:58:28.753196Z","iopub.status.busy":"2022-03-24T04:58:28.752784Z","iopub.status.idle":"2022-03-24T04:58:28.764083Z","shell.execute_reply":"2022-03-24T04:58:28.763281Z","shell.execute_reply.started":"2022-03-24T04:58:28.753158Z"},"trusted":true},"outputs":[],"source":["predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1).cpu().detach().numpy()\n","labels = labels.cpu().detach().numpy()\n","loss, macro_f1"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-03-24T04:58:28.765810Z","iopub.status.busy":"2022-03-24T04:58:28.765356Z","iopub.status.idle":"2022-03-24T04:58:28.773776Z","shell.execute_reply":"2022-03-24T04:58:28.772966Z","shell.execute_reply.started":"2022-03-24T04:58:28.765766Z"},"trusted":true},"outputs":[],"source":["confusion_matrix(labels, predicts)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([32, 1, 56])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from model.layers.poolers import CrossAttentionPooling\n","\n","cls_ = torch.rand((32,1,56)).squeeze()\n","seq = torch.rand((32,12,56))\n","h = CrossAttentionPooling(56)\n","h(cls_,seq).shape"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
