{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-01T10:12:55.240477Z","iopub.status.busy":"2022-04-01T10:12:55.240146Z","iopub.status.idle":"2022-04-01T10:12:57.760661Z","shell.execute_reply":"2022-04-01T10:12:57.759816Z","shell.execute_reply.started":"2022-04-01T10:12:55.240394Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/HuangRihChang/GSHSD.git\n","%cd GSHSD/GSHSD\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:12:57.762558Z","iopub.status.busy":"2022-04-01T10:12:57.762321Z","iopub.status.idle":"2022-04-01T10:13:06.208286Z","shell.execute_reply":"2022-04-01T10:13:06.207428Z","shell.execute_reply.started":"2022-04-01T10:12:57.762532Z"},"trusted":true},"outputs":[],"source":["from IPython.display import clear_output\n","import time\n","\n","!rm ./ngrok \n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","clear_output()\n","!./ngrok authtoken 23DuHXStdM98jNNlyZIVaHNFktk_8agkCvS2XmfuiY1yR5izh"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:06.212009Z","iopub.status.busy":"2022-04-01T10:13:06.211776Z","iopub.status.idle":"2022-04-01T10:13:28.363742Z","shell.execute_reply":"2022-04-01T10:13:28.362885Z","shell.execute_reply.started":"2022-04-01T10:13:06.211978Z"},"trusted":true},"outputs":[],"source":["! rm -r ./runs/\n","! mkdir \"./runs/\"\n","\n","LOG_DIR = './runs/'\n","get_ipython().system_raw(f'tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 2111 &')\n","get_ipython().system_raw('./ngrok http 2111 &')\n","time.sleep(10)\n","clear_output()\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n","time.sleep(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:28.366375Z","iopub.status.busy":"2022-04-01T10:13:28.366090Z","iopub.status.idle":"2022-04-01T10:13:47.402276Z","shell.execute_reply":"2022-04-01T10:13:47.401505Z","shell.execute_reply.started":"2022-04-01T10:13:28.366339Z"},"trusted":true},"outputs":[],"source":["# Install the vncorenlp python wrapper\n","!pip install vncorenlp\n","\n","# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter) \n","!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/\n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n","\n","clear_output()\n","# !pip install tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:47.404353Z","iopub.status.busy":"2022-04-01T10:13:47.403847Z","iopub.status.idle":"2022-04-01T10:13:47.415880Z","shell.execute_reply":"2022-04-01T10:13:47.415040Z","shell.execute_reply.started":"2022-04-01T10:13:47.404310Z"},"trusted":true},"outputs":[],"source":["from vncorenlp import VnCoreNLP\n","\n","class Segmentation:\n","    def __init__(self, api=\"./vncorenlp/VnCoreNLP-1.1.1.jar\", ):\n","        self.rdrsegmenter = VnCoreNLP(api, annotators=\"wseg\", max_heap_size='-Xmx500m')\n","\n","    def __call__(self, text):\n","        res = \"\"\n","        sentences = self.rdrsegmenter.tokenize(text.lower())\n","        for sentence in sentences:\n","            res += (\" \".join(sentence)) + \" \"\n","        return res.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:47.417821Z","iopub.status.busy":"2022-04-01T10:13:47.417456Z","iopub.status.idle":"2022-04-01T10:13:51.476434Z","shell.execute_reply":"2022-04-01T10:13:51.475676Z","shell.execute_reply.started":"2022-04-01T10:13:47.417786Z"},"trusted":true},"outputs":[],"source":["import functools\n","\n","import torch\n","from torch import nn\n","from model.model import TransformerEncoder\n","from model.metrices import F1Score\n","from model.losses.softmax import CenterLoss, FocalLoss\n","from HSDDataset import ViHSDData\n","\n","from torch.utils.data import DataLoader, RandomSampler\n","from tqdm.notebook import tqdm\n","# from tqdm import tqdm\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from torch.utils.tensorboard import SummaryWriter\n","from utils import get_device\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","import numpy as np\n","import emoji\n","import re\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:51.477935Z","iopub.status.busy":"2022-04-01T10:13:51.477682Z","iopub.status.idle":"2022-04-01T10:13:51.501054Z","shell.execute_reply":"2022-04-01T10:13:51.500296Z","shell.execute_reply.started":"2022-04-01T10:13:51.477902Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(8596)\n","\n","LR = 1e-6\n","n_epochs = 15\n","classes_num = 3\n","accum_iter = 2\n","batch_size = 64\n","checkpoint_batch_size = 1024\n","max_len = 128\n","device = get_device()\n","\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:51.502350Z","iopub.status.busy":"2022-04-01T10:13:51.502108Z","iopub.status.idle":"2022-04-01T10:13:57.133488Z","shell.execute_reply":"2022-04-01T10:13:57.131580Z","shell.execute_reply.started":"2022-04-01T10:13:51.502305Z"},"trusted":true},"outputs":[],"source":["segmentator = Segmentation()\n","\n","def proprocess(x):\n","    x = str(x)\n","    x = emoji.replace_emoji(x, replace='')\n","    x = segmentator(x)\n","    x = re.sub(r\" +\", \" \", x)\n","    return x.lower().strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:13:57.138848Z","iopub.status.busy":"2022-04-01T10:13:57.138490Z","iopub.status.idle":"2022-04-01T10:14:03.571391Z","shell.execute_reply":"2022-04-01T10:14:03.570633Z","shell.execute_reply.started":"2022-04-01T10:13:57.138797Z"},"trusted":true},"outputs":[],"source":["# Defining Model for specific fold \"vinai/phobert-base\"\n","# model_path = \"../../../input/mbert-model/bert-base-multilingual-uncased\"\n","model_path = \"../../../input/phobertpretrained/\"\n","# model_path = \"./weights/multiBERTuncased\"\n","\n","model = TransformerEncoder(model_path, classes_num = classes_num,\n","                            max_seq_length = max_len, \n","                            checkpoint_batch_size = checkpoint_batch_size,\n","                            dropout_rate = 0.1, \n","                            residial = True,\n","                            model_args = {\"output_hidden_states\":False}\n","                            )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:14:03.574836Z","iopub.status.busy":"2022-04-01T10:14:03.574106Z","iopub.status.idle":"2022-04-01T10:14:03.581762Z","shell.execute_reply":"2022-04-01T10:14:03.581032Z","shell.execute_reply.started":"2022-04-01T10:14:03.574796Z"},"trusted":true},"outputs":[],"source":["import random\n","\n","unk_token = model.tokenizer.unk_token\n","\n","def get_item(row, mask_rate=0.1):\n","    utterance, hate_label = row[\"free_text\"], row[\"label_id\"]\n","    utterance = utterance.split()\n","    mask_rate = random.uniform(0., mask_rate)\n","    start = random.randint(0,len(utterance))\n","    end = min(random.randint(start,len(utterance)), start+int(len(utterance)*mask_rate))\n","    tmp = utterance[0:start] + [unk_token]*(end-start) + utterance[end:]\n","    utterance = \" \".join(tmp)\n","    return utterance, hate_label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:14:03.583670Z","iopub.status.busy":"2022-04-01T10:14:03.582848Z","iopub.status.idle":"2022-04-01T10:16:32.311922Z","shell.execute_reply":"2022-04-01T10:16:32.311166Z","shell.execute_reply.started":"2022-04-01T10:14:03.583635Z"},"trusted":true},"outputs":[],"source":["model_collate_fn = functools.partial(lambda x: x)\n","\n","\n","train_df = pd.read_csv(\"./data/vihsd/train.csv\")\n","# max_ = 0\n","# for i in range(len(train_df.label_id.unique())):\n","#     tmp = train_df[train_df[\"label_id\"]==i]\n","#     if len(tmp) >= max_:\n","#         max_ = len(tmp)\n","\n","# for i in range(len(train_df.label_id.unique())):\n","#     tmp = train_df[train_df[\"label_id\"]==i]\n","#     for _ in range(math.ceil(max_/len(tmp))-1):\n","#         train_df = pd.concat([train_df, tmp])\n","\n","train_data = ViHSDData(train_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess,\n","                 augment_fnct=get_item,\n","                )\n","train_sampler = RandomSampler(train_data)\n","data_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n","\n","val_df = pd.read_csv(\"./data/vihsd/dev.csv\")\n","val_data = ViHSDData(val_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess\n","                )\n","val_sampler = RandomSampler(val_data)\n","val_loader = DataLoader(val_data, batch_size=batch_size, sampler=val_sampler, collate_fn=model_collate_fn)\n","\n","\n","test_df = pd.read_csv(\"./data/vihsd/test.csv\")\n","test_data = ViHSDData(test_df, \n","                 utterance_feild = \"free_text\", \n","                 label_feild=\"label_id\", \n","                 text_preprocessor=proprocess\n","                )\n","test_sampler = RandomSampler(test_data)\n","test_loader = DataLoader(test_data, batch_size=batch_size, sampler=test_sampler, collate_fn=model_collate_fn)\n","\n","training_step = len(data_loader)*n_epochs\n","print(f\"Total {training_step} training steps for this dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:16:32.314763Z","iopub.status.busy":"2022-04-01T10:16:32.313143Z","iopub.status.idle":"2022-04-01T10:16:32.331518Z","shell.execute_reply":"2022-04-01T10:16:32.330631Z","shell.execute_reply.started":"2022-04-01T10:16:32.314721Z"},"trusted":true},"outputs":[],"source":["labels = list(train_df.label_id.unique())\n","for i in labels:\n","    tmp = train_df[train_df.label_id == i]\n","    print(len(tmp), 1 - len(tmp)/len(train_df))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:16:32.333375Z","iopub.status.busy":"2022-04-01T10:16:32.333110Z","iopub.status.idle":"2022-04-01T10:16:36.979675Z","shell.execute_reply":"2022-04-01T10:16:36.977836Z","shell.execute_reply.started":"2022-04-01T10:16:32.333339Z"},"trusted":true},"outputs":[],"source":["# cross_entropy_loss = nn.CrossEntropyLoss()\n","classes_weights = torch.Tensor([0.1730705256154358, 0.8937125748502994, 0.9332168995342648]).to(device)\n","cross_entropy_loss = FocalLoss(alpha = classes_weights, gamma=1.2)\n","\n","center_loss = CenterLoss(num_class=classes_num,\\\n","                         num_feature = model.get_word_embedding_dimension()\n","                        )\n","\n","model.to(device)\n","cross_entropy_loss.to(device)\n","center_loss.to(device)\n","\n","model_params = list(model.named_parameters()) # included all params from pooler and transformers\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","model_params = [{'params': [p for n, p in model_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n","                {'params': [p for n, p in model_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","               ]\n","\n","opt_params = model_params\n","\n","model_optimizer = AdamW(opt_params, lr=LR)\n","model_scheduler = get_linear_schedule_with_warmup(model_optimizer,\n","                                            num_warmup_steps=training_step*0.5, \n","                                            num_training_steps=training_step\n","                                            )\n","\n","center_loss_params = list(center_loss.named_parameters())\n","center_loss_params = [{'params': [p for n, p in center_loss_params], 'weight_decay': 0.0},]\n","center_loss_optimizer = AdamW(center_loss_params, lr=0.1)\n","center_loss_scheduler = get_linear_schedule_with_warmup(center_loss_optimizer,\n","                                            num_warmup_steps=training_step*0.5, \n","                                            num_training_steps=training_step\n","                                            )\n","# for param in model.sent_encoder.embeddings.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:16:36.981297Z","iopub.status.busy":"2022-04-01T10:16:36.981065Z","iopub.status.idle":"2022-04-01T10:16:36.990810Z","shell.execute_reply":"2022-04-01T10:16:36.990032Z","shell.execute_reply.started":"2022-04-01T10:16:36.981264Z"},"trusted":true},"outputs":[],"source":["def make_batch(batch, tokenizer, max_len=\"dynamic\", device=\"cuda:0\"):\n","    text_list, labels = [text for text,_ in batch], [label for _,label in batch]\n","    \n","    if max_len == \"dynamic\":\n","        lengths = np.array([len(tokenizer.tokenize(x))+2 for x in text_list])\n","        max_len = int(lengths.max())\n","    \n","    labels = torch.LongTensor(labels).to(device)\n","    toks = tokenizer.batch_encode_plus(text_list, max_length=max_len, padding='max_length', truncation=True)\n","    ids, mask = (torch.LongTensor(toks[\"input_ids\"]).to(device), torch.LongTensor(toks[\"attention_mask\"]).to(device))\n","    inputs = {\"input_ids\": ids, \"attention_mask\": mask}\n","    return inputs, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:16:36.992506Z","iopub.status.busy":"2022-04-01T10:16:36.992222Z","iopub.status.idle":"2022-04-01T10:16:37.013883Z","shell.execute_reply":"2022-04-01T10:16:37.012902Z","shell.execute_reply.started":"2022-04-01T10:16:36.992469Z"},"trusted":true},"outputs":[],"source":["def train(data_loader, model, cross_entropy_loss, center_loss, train_step):\n","    tk = tqdm(data_loader)\n","    f1 = F1Score()\n","    model.train()\n","    for i, x in enumerate(tk):\n","        inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n","        if train_step == 0:\n","            writer.add_graph(model, inputs)\n","        \n","        with torch.set_grad_enabled(True):\n","            logits, features = model(inputs)\n","            celoss = cross_entropy_loss(logits, labels)\n","            loss = celoss + 0.001*center_loss(features, labels)\n","            loss.backward()\n","        \n","        \n","        if ((i + 1) % accum_iter == 0) or (i + 1 == len(data_loader)):\n","            for param in center_loss.parameters():\n","                if param.grad is not None:\n","                    param.grad *= 1/0.0001\n","\n","            model_optimizer.step()\n","            center_loss_optimizer.step()\n","            model_scheduler.step()\n","            center_loss_scheduler.step()\n","            model_optimizer.zero_grad()\n","            center_loss_optimizer.zero_grad()\n","        \n","        with torch.no_grad():\n","            predict = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n","            macro_f1 = f1(predict+1, labels+1, \"macro\")\n","            tk.set_postfix(Epoch=e, step=train_step, loss=loss.data.item(), f1=macro_f1[0].data.item())\n","            writer.add_scalar('loss', loss.data.item(), train_step)\n","            writer.add_scalar('celoss', celoss.data.item(), train_step)\n","            writer.add_scalar('macro_f1', macro_f1[0].data.item(), train_step)\n","        train_step += 1\n","    return train_step\n","\n","\n","def evaluation(dev_loader, model, cross_entropy_loss, prefix=None):\n","    f1 = F1Score()\n","    logits_list, labels_list = [], []\n","    model.eval()\n","    with torch.no_grad():\n","        for x in dev_loader:\n","            inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n","            logits, _ = model(inputs)\n","            logits_list.append(logits)\n","            labels_list.append(labels)\n","        labels = torch.cat(labels_list, dim=0)\n","        logits = torch.cat(logits_list, dim=0)\n","        predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n","        macro_f1 = f1(predicts+1, labels+1, \"macro\")\n","        loss = cross_entropy_loss(logits, labels)\n","        print(f\"Epoch {e} - loss: {loss.data.item()} - F1: {macro_f1[0].data.item()}\")\n","        if prefix is not None:\n","            writer.add_scalar(f'{prefix} celoss', loss.data.item(), e)\n","            writer.add_scalar(f'{prefix} macro_f1', macro_f1[0].data.item(), e)\n","            \n","        print(confusion_matrix(labels.cpu().detach().numpy(), \n","                               torch.argmax(torch.softmax(logits, dim=-1), dim=-1).cpu().detach().numpy()))\n","    return logits, labels, loss, macro_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-01T10:16:37.015564Z","iopub.status.busy":"2022-04-01T10:16:37.015222Z"},"trusted":true},"outputs":[],"source":["! rm -r ./runs/\n","! mkdir \"./runs/\"\n","writer = SummaryWriter()\n","\n","train_step = 0\n","best_f1 = 0\n","best_loss = 1e8\n","for e in range(n_epochs):\n","    train_step = train(data_loader, model, cross_entropy_loss, center_loss, train_step)\n","    _, _, loss, macro_f1 = evaluation(val_loader, model, cross_entropy_loss,  prefix=\"val\")\n","    \n","    val_loss = loss.data.item()\n","    val_f1_score = macro_f1[0].data.item()\n","    \n","    if best_f1 <= val_f1_score:\n","        best_f1 = val_f1_score\n","        print(f\"Epcoh {e} Saving best f1_model with score {best_f1}\")\n","        torch.save(model.state_dict(), f\"best_f1.pth\")\n","    \n","    if best_loss >= val_loss:\n","        best_loss = val_loss\n","        print(f\"Epcoh {e} Saving best loss model with score {best_loss}\")\n","        torch.save(model.state_dict(), f\"best_loss.pth\")\n","\n","logits, labels, loss, macro_f1 = evaluation(test_loader, model, cross_entropy_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.load_state_dict(torch.load(\"best_f1.pth\"))\n","model.eval()\n","e = 11\n","logits, labels, loss, macro_f1 = evaluation(test_loader, model, cross_entropy_loss)\n","predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1).cpu().detach().numpy()\n","labels = labels.cpu().detach().numpy()\n","loss, macro_f1, confusion_matrix(labels, predicts)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.load_state_dict(torch.load(\"best_loss.pth\"))\n","model.eval()\n","e = 11\n","logits, labels, loss, macro_f1 = evaluation(test_loader, model, cross_entropy_loss)\n","predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1).cpu().detach().numpy()\n","labels = labels.cpu().detach().numpy()\n","loss, macro_f1, confusion_matrix(labels, predicts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
