{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/HuangRihChang/GSHSD.git\n%cd GSHSD/GSHSD\n!ls","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-03-22T14:54:48.194202Z","iopub.execute_input":"2022-03-22T14:54:48.194796Z","iopub.status.idle":"2022-03-22T14:54:49.731922Z","shell.execute_reply.started":"2022-03-22T14:54:48.194691Z","shell.execute_reply":"2022-03-22T14:54:49.730869Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import functools\n\nimport torch\nfrom torch import nn\nfrom model.model import TransformerEncoder\nfrom model.metrices import F1Score\nfrom HSDDataset import ViHSDData\n\nfrom torch.utils.data import DataLoader, RandomSampler\nfrom tqdm.notebook import tqdm\n# from tqdm import tqdm\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.tensorboard import SummaryWriter\nfrom utils import get_device\nfrom sklearn.metrics import f1_score\nimport pandas as pd\nimport emoji\nimport re\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:54:59.296599Z","iopub.execute_input":"2022-03-22T14:54:59.296908Z","iopub.status.idle":"2022-03-22T14:55:02.205672Z","shell.execute_reply.started":"2022-03-22T14:54:59.296875Z","shell.execute_reply":"2022-03-22T14:55:02.204690Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"LR = 1e-4\nn_epochs = 25\nclasses_num = 3\nbatch_size = 64\ncheckpoint_batch_size = 1024\nmax_len = 128\ndevice = get_device()\n\nwriter = SummaryWriter()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:05.611753Z","iopub.execute_input":"2022-03-22T14:55:05.612416Z","iopub.status.idle":"2022-03-22T14:55:05.656614Z","shell.execute_reply.started":"2022-03-22T14:55:05.612379Z","shell.execute_reply":"2022-03-22T14:55:05.655326Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def proprocess(x):\n    x = str(x)\n    x = emoji.replace_emoji(x, replace='')\n    x = re.sub(r\" +\", \" \", x)\n    return x.lower().strip()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:07.035794Z","iopub.execute_input":"2022-03-22T14:55:07.036716Z","iopub.status.idle":"2022-03-22T14:55:07.043524Z","shell.execute_reply.started":"2022-03-22T14:55:07.036669Z","shell.execute_reply":"2022-03-22T14:55:07.042388Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_collate_fn = functools.partial(lambda x: x)\n\n\ntrain_df = pd.read_csv(\"./data/vihsd/train.csv\")\nmax_ = 0\nfor i in range(len(train_df.label_id.unique())):\n    tmp = train_df[train_df[\"label_id\"]==i]\n    if len(tmp) >= max_:\n        max_ = len(tmp)\n\nfor i in range(len(train_df.label_id.unique())):\n    tmp = train_df[train_df[\"label_id\"]==i]\n    for _ in range(math.ceil(max_/len(tmp))-1):\n        train_df = pd.concat([train_df, tmp])\n\ntrain_data = ViHSDData(train_df, \n                 utterance_feild = \"free_text\", \n                 label_feild=\"label_id\", \n                 text_preprocessor=proprocess\n                )\ntrain_sampler = RandomSampler(train_data)\ndata_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n\nval_df = pd.read_csv(\"./data/vihsd/dev.csv\")\nval_data = ViHSDData(val_df, \n                 utterance_feild = \"free_text\", \n                 label_feild=\"label_id\", \n                 text_preprocessor=proprocess\n                )\nval_sampler = RandomSampler(val_data)\nval_loader = DataLoader(val_data, batch_size=batch_size, sampler=val_sampler, collate_fn=model_collate_fn)\n\n\ntest_df = pd.read_csv(\"./data/vihsd/test.csv\")\ntest_data = ViHSDData(test_df, \n                 utterance_feild = \"free_text\", \n                 label_feild=\"label_id\", \n                 text_preprocessor=proprocess\n                )\ntest_sampler = RandomSampler(test_data)\ntest_loader = DataLoader(test_data, batch_size=batch_size, sampler=test_sampler, collate_fn=model_collate_fn)\n\ntraining_step = len(data_loader)*n_epochs\nprint(f\"Total {training_step} training steps for this dataset\")","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:08.145974Z","iopub.execute_input":"2022-03-22T14:55:08.147166Z","iopub.status.idle":"2022-03-22T14:55:11.502036Z","shell.execute_reply.started":"2022-03-22T14:55:08.147121Z","shell.execute_reply":"2022-03-22T14:55:11.500943Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Defining Model for specific fold \"vinai/phobert-base\"\nmodel = TransformerEncoder(\"../../../input/mbert-model/bert-base-multilingual-uncased\", classes_num = classes_num,\n                            max_seq_length = max_len, \n                            checkpoint_batch_size = checkpoint_batch_size,\n                            dropout_rate = 0.5, \n                            model_args = {\"output_hidden_states\":False}\n                            )\n\ncross_entropy_loss = nn.CrossEntropyLoss()\n\nmodel.to(device)\ncross_entropy_loss.to(device)\n\n\nmodel_params = list(model.named_parameters()) # included all params from pooler and transformers\nno_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\nmodel_params = [{'params': [p for n, p in model_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n                {'params': [p for n, p in model_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n               ]\noptimizer = AdamW(model_params, lr=LR)\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps=training_step*0.5, \n                                            num_training_steps=training_step\n                                            )\n\n# for param in model.sent_encoder.embeddings.parameters():\n#     param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:11.504740Z","iopub.execute_input":"2022-03-22T14:55:11.505158Z","iopub.status.idle":"2022-03-22T14:55:17.302666Z","shell.execute_reply.started":"2022-03-22T14:55:11.505114Z","shell.execute_reply":"2022-03-22T14:55:17.301718Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def make_batch(batch, tokenizer, max_len=64, device=\"cuda:0\"):\n    text_list, labels = [text for text,_ in batch], [label for _,label in batch]\n    labels = torch.LongTensor(labels).to(device)\n    toks = tokenizer.batch_encode_plus(text_list, max_length=max_len, padding='max_length', truncation=True)\n    ids, mask = (torch.LongTensor(toks[\"input_ids\"]).to(device), torch.LongTensor(toks[\"attention_mask\"]).to(device))\n    inputs = {\"input_ids\": ids, \"attention_mask\": mask}\n    return inputs, labels","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:17.307935Z","iopub.execute_input":"2022-03-22T14:55:17.310550Z","iopub.status.idle":"2022-03-22T14:55:17.362177Z","shell.execute_reply.started":"2022-03-22T14:55:17.310501Z","shell.execute_reply":"2022-03-22T14:55:17.361026Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, cross_entropy_loss, optimizer, scheduler, train_step):\n    tk = tqdm(data_loader)\n    f1 = F1Score()\n    for x in tk:\n        model.train()\n        inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n        optimizer.zero_grad()\n        logits = model(inputs)\n        loss = cross_entropy_loss(logits, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        with torch.no_grad():\n            model.eval()\n            predict = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n            macro_f1 = f1(predict+1, labels+1, \"macro\")\n            tk.set_postfix(Epoch=e, step=train_step, loss=loss.data.item(), f1=macro_f1[0].data.item())\n        train_step += 1\n    return train_step\n\n\ndef evaluation(dev_loader, model, cross_entropy_loss):\n    f1 = F1Score()\n    logits_list, labels_list = [], []\n    model.eval()\n    with torch.no_grad():\n        for x in dev_loader:\n            inputs, labels = make_batch(x, model.tokenizer, max_len=max_len, device=device)\n            logits = model(inputs)\n            logits_list.append(logits)\n            labels_list.append(labels)\n        labels = torch.cat(labels_list, dim=0)\n        logits = torch.cat(logits_list, dim=0)\n        predicts = torch.argmax(torch.softmax(logits, dim=-1), dim=-1)\n        macro_f1 = f1(predicts+1, labels+1, \"macro\")\n        loss = cross_entropy_loss(logits, labels)\n        print(f\"Epoch {e} - loss: {loss.data.item()} - F1: {macro_f1[0].data.item()}\")\n    return logits, labels, loss, macro_f1","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:17.364962Z","iopub.execute_input":"2022-03-22T14:55:17.365335Z","iopub.status.idle":"2022-03-22T14:55:17.382675Z","shell.execute_reply.started":"2022-03-22T14:55:17.365282Z","shell.execute_reply":"2022-03-22T14:55:17.381580Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_step = 0\nfor e in range(n_epochs):\n    train_step = train(data_loader, model, cross_entropy_loss, optimizer, scheduler, train_step)\n    evaluation(val_loader, model, cross_entropy_loss)\nevaluation(test_loader, model, cross_entropy_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:55:17.383961Z","iopub.execute_input":"2022-03-22T14:55:17.384527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation(test_loader, model, cross_entropy_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}